{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the data from train file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist_data():\n",
    "    \n",
    "    data=pd.read_csv('train.csv', sep=',').as_matrix()\n",
    "    data.shape\n",
    "    N = data.shape[0]\n",
    "    n_train = int((N*70)/100)\n",
    "    X_train = np.column_stack((data[:n_train,1:], np.ones((n_train,1))))\n",
    "    Y_train = data[:n_train,0]\n",
    "\n",
    "    X_test = np.column_stack((data[n_train:,1:], np.ones((N-n_train,1))))\n",
    "    Y_test = data[n_train:,0]\n",
    "\n",
    "    C = 10\n",
    "    d = X_train.shape[1]\n",
    "    return data, N, n_train, X_train, Y_train, X_test, Y_test, C, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the data into training and testing data\n",
    "data, N, n_train, X_train, Y_train, X_test, Y_test, C, d = load_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# First implement a gradient checker by filling in the following functions\n",
    "def gradcheck_naive(f, x):\n",
    "    \"\"\" \n",
    "    Gradient check for a function f \n",
    "    - f should be a function that takes a single argument and outputs the cost and its gradients\n",
    "    - x is the point (numpy array) to check the gradient at\n",
    "    \"\"\" \n",
    "\n",
    "    rndstate = random.getstate()\n",
    "    random.setstate(rndstate)  \n",
    "    fx, grad = f(x) # Evaluate function value at original point\n",
    "    h = 1e-5\n",
    "\n",
    "    # Iterate over all indexes in x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "        \n",
    "        ### YOUR CODE HERE: try modifying x[ix] with h defined above to compute numerical gradients\n",
    "        ### make sure you call random.setstate(rndstate) before calling f(x) each time, this will make it \n",
    "        ### possible to test cost functions with built in randomness later\n",
    "        \n",
    "        x[ix] = x[ix]+h\n",
    "        \n",
    "        random.setstate(rndstate)\n",
    "        fx1,grad1 = f(x)\n",
    "        numgrad = (fx1-fx)/h\n",
    "        \n",
    "        x[ix] = x[ix]-h\n",
    "        \n",
    "        ### END YOUR CODE\n",
    "\n",
    "        # Compare gradients\n",
    "        reldiff = abs(numgrad - grad[ix]) / max(1, abs(numgrad), abs(grad[ix]))\n",
    "        if reldiff > 1e-5:\n",
    "            print( \"Gradient check failed.\")\n",
    "            print( \"First gradient error found at index %s\" % str(ix))\n",
    "            print( \"Your gradient: %f \\t Numerical gradient: %f\" % (grad[ix], numgrad))\n",
    "            return\n",
    "        \n",
    "        it.iternext() # Step to next dimension\n",
    "\n",
    "    print( \"Gradient check passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "theta = np.random.rand(C, d)*0.0001\n",
    "def svm_loss_grad(W, X, Y, reg = 1e-3):\n",
    "    N = X.shape[0]\n",
    "    #C = np.max(Y) + 1\n",
    "    scores = X.dot(W.T)\n",
    "    l = scores-scores[np.arange(N), Y].reshape(-1,1) + 1\n",
    "    l[np.arange(N), Y] = 0\n",
    "    l = np.maximum(l, 0)\n",
    "    loss = np.sum(l)\n",
    "    loss /= N\n",
    "    loss += 0.5 * reg * np.sum(W*W)\n",
    "    \n",
    "    I = l > 0\n",
    "    IA = np.sum(I, axis=1)\n",
    "    Y_m = np.zeros((N, C))\n",
    "    Y_m[np.arange(N), Y] = 1\n",
    "    grad = I.T.dot(X)\n",
    "    grad -= Y_m.T.dot(X*IA.reshape(-1,1))\n",
    "    grad /= N\n",
    "    grad += reg * W\n",
    "    return loss, grad\n",
    "\n",
    "def predict(W, X, reg = 1e-3):\n",
    "    scores = X.dot(W.T)\n",
    "    return np.argmax(scores, axis=1)\n",
    "    \n",
    "gradcheck_naive(lambda q : svm_loss_grad(q, X_train[0:5], Y_train[0:5]), W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8EtFGX6pKMMvFfX/ViuIsyHvWZMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110feb470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the image just so that you can see how they are\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "n = 38\n",
    "imgplot = plt.imshow(X_train[n,:-1].reshape(28,28))\n",
    "Y_train[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-72e815e18e65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m training_error, testing_error, theta, train_accuracy, test_accuracy = gradient_descent(svm_loss_grad, predict, theta, X_train, Y_train, X_test, Y_test,\n\u001b[0;32m---> 35\u001b[0;31m                                                         print_iteration=100, max_iterations=100,learning_rate=1e-7)\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-72e815e18e65>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(f, predict, theta, Xr, Yr, Xe, Ye, batch_size, max_iterations, print_iteration, learning_rate)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-214766f7d2b4>\u001b[0m in \u001b[0;36msvm_loss_grad\u001b[0;34m(W, X, Y, reg)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "def gradient_descent(f, predict, theta, Xr, Yr, Xe, Ye, batch_size=5, max_iterations=100, print_iteration=10, learning_rate=0.0001):\n",
    "    N_train = Xr.shape[0]\n",
    "    batch_count = int(N_train/batch_size)\n",
    "    it = 0\n",
    "    training_error = []\n",
    "    testing_error = []\n",
    "    while it < max_iterations:\n",
    "        #pick a batch\n",
    "        batch = random.randint(0, batch_count)\n",
    "        if(batch < batch_count-1):\n",
    "            X, Y = Xr[batch:batch+batch_size], Yr[batch:batch+batch_size]\n",
    "        else:\n",
    "            X, Y = Xr[batch:], Yr[batch:]\n",
    "        cost, grad = f(theta, X, Y)\n",
    "        theta -= learning_rate*grad\n",
    "        \n",
    "        if it%print_iteration == 0:\n",
    "            training_cost = f(theta, Xr, Yr)[0]\n",
    "            testing_cost = f(theta, Xe, Ye)[0]\n",
    "            training_error.append(training_cost)\n",
    "            testing_error.append(testing_cost)\n",
    "            #print(\"Iteration %d\\t Training cost %f\\t Testing cost %f\\t\"%(it, training_cost, testing_cost))\n",
    "        \n",
    "        it += 1\n",
    "    \n",
    "    Y_testp = predict(theta, Xe)\n",
    "    Y_trainp = predict(theta, Xr)\n",
    "\n",
    "    test_accuracy = np.mean(Y_testp==Ye)*100\n",
    "    train_accuracy = np.mean(Y_trainp==Yr)*100\n",
    "    return training_error, testing_error, theta, train_accuracy, test_accuracy\n",
    "\n",
    "\n",
    "training_error, testing_error, theta, train_accuracy, test_accuracy = gradient_descent(svm_loss_grad, predict, theta, X_train, Y_train, X_test, Y_test,\n",
    "                                                        print_iteration=100, max_iterations=100,learning_rate=1e-7)\n",
    "\n",
    "x = range(len(training_error))\n",
    "plt.plot(x, training_error, x, testing_error)\n",
    "plt.show()\n",
    "\n",
    "print(test_accuracy, train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
